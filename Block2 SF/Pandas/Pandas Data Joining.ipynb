{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2000\n",
       "1         2000\n",
       "2         2000\n",
       "3         2000\n",
       "4         2000\n",
       "          ... \n",
       "100831    2017\n",
       "100832    2017\n",
       "100833    2017\n",
       "100834    2017\n",
       "100835    2017\n",
       "Name: date, Length: 100836, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Наши данные представляют собой четыре таблицы:\n",
    "\n",
    "ratings1 и ratings2 — таблицы с данными о выставленных пользователями оценках фильмов. \n",
    "Они имеют одинаковую структуру и типы данных — на самом деле это две части одной таблицы \n",
    "с оценками фильмов.\n",
    "userId — уникальный идентификатор пользователя, который выставил оценку;\n",
    "movieId — уникальный идентификатор фильма;\n",
    "rating — рейтинг фильма.\n",
    "\n",
    "dates — таблица с датами выставления всех оценок.\n",
    "date — дата и время выставления оценки фильму.\n",
    "\n",
    "movies — таблица с информацией о фильмах.\n",
    "movieId — уникальный идентификатор фильма;\n",
    "title — название фильма и год его выхода;\n",
    "genres — жанры фильма.\"\"\"\n",
    "import pandas as pd\n",
    "movies = pd.read_csv('data_test/movies.csv')\n",
    "#Сколько уникальных фильмов представлено в таблице movies?\n",
    "movies['movieId'].nunique()\n",
    "#Сколько уникальных пользователей в таблице ratings1?\n",
    "ratings1_df = pd.read_csv('data_test/ratings1.csv')\n",
    "ratings2_df = pd.read_csv('data_test/ratings2.csv')\n",
    "ratings1_df['userId'].nunique()\n",
    "#В каком году было выставлено больше всего оценок?...используйте таблицу dates.\n",
    "dates = pd.read_csv('data_test/dates.csv')\n",
    "pd.to_datetime(dates['date']).dt.year\n",
    "\n",
    "#years_dates = dates.dt.year\n",
    "#print (years_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings in table \"ratings\": (100837, 3)\n",
      "Number of strings in table \"dates\": (100836, 1)\n",
      "False\n",
      "Number of rows in table\"ratings\": 100836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100829</th>\n",
       "      <td>610</td>\n",
       "      <td>164179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:07:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100830</th>\n",
       "      <td>610</td>\n",
       "      <td>166528</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-04 06:29:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:53:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 22:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-08 19:50:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:20:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating                 date\n",
       "100829     610   164179     5.0  2017-05-03 21:07:11\n",
       "100830     610   166528     4.0  2017-05-04 06:29:25\n",
       "100831     610   166534     4.0  2017-05-03 21:53:22\n",
       "100832     610   168248     5.0  2017-05-03 22:21:31\n",
       "100833     610   168250     5.0  2017-05-08 19:50:47\n",
       "100834     610   168252     5.0  2017-05-03 21:19:12\n",
       "100835     610   170875     3.0  2017-05-03 21:20:15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Итак, давайте склеим  ratings1 и ratings2 по строкам, так как они имеют одинаковую структуру \n",
    "столбцов. Для этого передадим их списком в функцию concat(). Помним, что параметр axis по умолчанию \n",
    "равен 0, объединение происходит по строкам, поэтому не трогаем его. \n",
    "Примечание. Обратите внимание, что concat является функцией библиотеки, а не методом DataFrame.\n",
    "Поэтому её вызов осуществляется как pd.concat(...).\"\"\"\n",
    "ratings = pd.concat([ratings1_df,ratings2_df])\n",
    "ratings\n",
    "#по умолчанию concat сохраняет первоначальные индексы объединяемых таблиц, а обе наши таблицы индексировались,\n",
    "#начиная от 0. Чтобы создать новые индексы, нужно выставить параметр ignore_index на True:\n",
    "ratings = pd.concat([ratings1_df,ratings2_df],ignore_index=True)\n",
    "ratings\n",
    "#Казалось бы, совсем другое дело! Но это ещё не всё. Давайте узнаем количество строк в таблицах\n",
    "#ratings и dates, ведь нам предстоит вертикально склеить их между собой:\n",
    "print ('Number of strings in table \"ratings\":',ratings.shape)\n",
    "print ('Number of strings in table \"dates\":',dates.shape)\n",
    "print (ratings.shape[0] == dates.shape[0])\n",
    "\"\"\"Pазмерность таблиц разная — как такое могло произойти?\n",
    "На самом деле очень просто: при выгрузке данных информация об оценках какого-то пользователя попала\n",
    "в обе таблицы (ratings1 и ratings2). В результате конкатенации случилось дублирование строк. \n",
    "В данном примере их легко найти — выведем последнюю строку таблицы ratings1 и первую строку \n",
    "таблицы ratings2:\"\"\"\n",
    "ratings1_df.tail(1)\n",
    "ratings2_df.head(1)\n",
    "\"\"\"Чтобы очистить таблицу от дублей, мы можем воспользоваться методом DataFrame drop_duplicates(),\n",
    "который удаляет повторяющиеся строки в таблице. Не забываем обновить индексы после удаления дублей,\n",
    "выставив параметр ignore_index в методе drop_duplicates() на значение True:\"\"\"\n",
    "ratings = ratings.drop_duplicates(ignore_index=True)\n",
    "print('Number of rows in table\"ratings\":',ratings.shape[0])\n",
    "#Наконец, мы можем добавить к нашей таблице с оценками даты их выставления.\n",
    "#Для этого конкатенируем таблицы ratings и dates по столбцам:\n",
    "ratings_dates = pd.concat([ratings,dates], axis=1)\n",
    "ratings_dates.tail(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: './Root/users/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 29\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"Допустим, в ваше распоряжение предоставлена директория \"./Root/users/\". В данной директории \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mсодержатся csv-файлы, в каждом из которых хранится информация об идентификаторах пользователей \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m(user_id) и ссылки на их фотографии (photo_url). Каждый файл из папки users имеет примерно \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mУчтите, что на тестовом наборе файлов в результате объединения могут возникнуть дубликаты, \u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mот которых необходимо будет избавиться.\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m./Root/users/\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: './Root/users/'"
     ]
    }
   ],
   "source": [
    "\"\"\"Допустим, в ваше распоряжение предоставлена директория \"./Root/users/\". В данной директории \n",
    "содержатся csv-файлы, в каждом из которых хранится информация об идентификаторах пользователей \n",
    "(user_id) и ссылки на их фотографии (photo_url). Каждый файл из папки users имеет примерно \n",
    "следующую структуру:\n",
    "Img\n",
    "При проверке в директории может быть сколько угодно файлов (директория может изменяться в \n",
    "зависимости от устройства файловой системы).\n",
    "Вам необходимо написать функцию concat_user_files(path), параметром которой является path — путь \n",
    "до директории. Функция должна объединить информацию из предоставленных вам файлов в один DataFrame\n",
    "и вернуть его. \n",
    "Список названий всех файлов, находящихся в директории, вы можете получить с помощью функции \n",
    "os.listdir(path) из модуля os (модуль уже импортирован в файле main.py). Например, для директории\n",
    "\"./Root/users/\" результатом работы функции будет список:\n",
    "print(os.listdir('./Root/users/'))\n",
    "['users2.csv', 'users1.csv', 'users3.csv']\n",
    "Примечание. Модуль os позволяет работать с операционной системой компьютера прямо из кода.\n",
    "Подробнее о нем вы можете почитать здесь.\n",
    "Отсортируйте этот список, прежде чем производить объединение файлов.\n",
    "Когда вы получите отсортированный список, вам останется только прочитать все csv-файлы из списка \n",
    "в цикле и объединить прочитанные таблицы между собой.\n",
    "Однако обратите внимание, что метод os.listdir() возвращает только список имён файлов в указанной\n",
    "директории, а при чтении файла необходимо указывать полный путь до него. То есть путь для чтения\n",
    "будет таким:\n",
    "'./Root/users/{file_name}'\n",
    "Не забудьте обновить индексы результирующей таблицы после объединения.\n",
    "Учтите, что на тестовом наборе файлов в результате объединения могут возникнуть дубликаты, \n",
    "от которых необходимо будет избавиться.\"\"\"\n",
    "import os\n",
    "print(os.listdir('./Root/users/'))\n",
    "import pandas as pd\n",
    "\"\"\"Вам необходимо написать функцию concat_user_files(path), параметром которой является path \n",
    "- путь до директории. Функция должна объединить информацию из предоставленных вам файлов в \n",
    "один DataFrame и вернуть его. Не забудьте обновить индексы результирующей таблицы после объединения.\n",
    "Учтите тот момент, что в результате объединения могут возникнуть дубликаты, от которых необходимо\n",
    "будет избавиться. \"\"\"\n",
    "    \n",
    "def concat_users_files(path):\n",
    "    data = pd.DataFrame()\n",
    "    file_names = os.listdir(path)\n",
    "    file_names.sort()\n",
    "    for file in file_names:\n",
    "        tmp_data = pd.read_csv(path + '/' + file)\n",
    "        data = pd.concat([data, tmp_data], axis=0, ignore_index=True)\n",
    "    data = data.drop_duplicates()\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = concat_users_files('./Root/users/')\n",
    "\n",
    "['users1.csv', 'users3.csv', 'users2.csv']\n",
    "                          image_url user_id\n",
    "0  http://example.com/img/id001.png   id001\n",
    "1  http://example.com/img/id002.jpg   id002\n",
    "2  http://example.com/img/id003.bmp   id003\n",
    "3  http://example.com/img/id004.jpg   id004\n",
    "4  http://example.com/img/id005.png   id005\n",
    "5  http://example.com/img/id006.png   id006\n",
    "6  http://example.com/img/id007.png   id007\n",
    "7  http://example.com/img/id008.png   id008\n",
    "\n",
    "[8 rows x 2 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19729490"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Основные параметры метода join()\n",
    "\n",
    "other — таблица, которую мы присоединяем. При объединении она является «правой», а исходная \n",
    "таблица, от имени которой вызывается метод, является «левой».\n",
    "how — параметр типа объединения. Он может принимать значения 'inner', 'left' (left outer), 'right'\n",
    "(right outer), и 'outer' (full outer). По умолчанию параметр установлен на 'left'.\n",
    "on — параметр, который определяет, по какому столбцу в «левой» таблице происходит объединение\n",
    "по индексам из «правой».\n",
    "lsuffix и rsuffix — дополнения (суффиксы) к названиям одноимённых столбцов в «левой» и «правой» таблицах.\"\"\"\n",
    "joined_false = ratings_dates.join(\n",
    "    movies,\n",
    "    rsuffix='_right',\n",
    "    how='left'\n",
    ")\n",
    "joined_false\n",
    "\"\"\"Обратите внимание, что в данном случае у нас получилось два столбца, соответствующих \n",
    "идентификатору фильма: один — из «левой» таблицы (movieId), а другой — из «правой» (movieId_right).\n",
    "Однако это не тот результат, который мы хотели, ведь мы не получили соответствия фильмов и их \n",
    "рейтингов. Чтобы совместить таблицы по ключевому столбцу с помощью метода join(), необходимо \n",
    "использовать ключевой столбец в «правой» таблице в качестве индекса. Это можно сделать с помощью \n",
    "метода set_index(). Также необходимо указать название ключа в параметре on.\"\"\"\n",
    "joined = ratings_dates.join(\n",
    "    movies.set_index('movieId'),\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "joined.head()\n",
    "\n",
    "\"\"\"Аналогично предыдущему, метод merge() предназначен для слияния двух таблиц по ключевым столбцам\n",
    "или по индексам. Однако, в отличие от join(), метод merge() предлагает более гибкий способ\n",
    "управления объединением, благодаря чему является более популярным.\n",
    "Основные параметры метода merge():\n",
    "right — присоединяемая таблица. По умолчанию она является «правой».\n",
    "how — параметр типа объединения. По умолчанию принимает значение 'inner'.\n",
    "on — параметр, который определяет, по какому столбцу происходит объединение. Определяется \n",
    "автоматически, но рекомендуется указывать вручную.\n",
    "left_on — если названия столбцов в «левой» и «правой» таблицах не совпадают, то данный параметр \n",
    "отвечает за наименования ключевого столбца исходной таблицы.\n",
    "right_on — аналогично предыдущему, параметр отвечает за наименование ключевого столбца \n",
    "присоединяемой таблицы.\n",
    "Метод merge() в первую очередь предназначен для слияния таблиц по заданным ключам, поэтому он не \n",
    "требует установки ключевых столбцов в качестве индекса присоединяемой таблицы. Кроме того, \n",
    "данный метод позволяет объединять даже таблицы с разноимёнными ключами. Таким образом, merge() \n",
    "проще в использовании и более многофункционален, чем схожие методы.\"\"\"\n",
    "merged = ratings_dates.merge(\n",
    "    movies,\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "merged.head()\n",
    "#Проверим, что число строк в таблице ratings_dates совпадает с числом строк в результирующей\n",
    "# таблице merged:\n",
    "'Numbers of rows in table\"ratings_dates:\"',ratings_dates.shape[0]\n",
    "'Numbers of rows in table\"merged:\"',merged.shape[0]\n",
    "ratings_dates.shape[0] == merged.shape[0]\n",
    "#Возникает вопрос: почему мы выбрали тип объединения left, а не full, например?\n",
    "#Найти ответ нам поможет пример. Объединим ratings_dates с movies по ключевому столбцу movieId,\n",
    "#но с параметром how='outer' (full outer) и выведем размер таблицы, а также её «хвост»:\n",
    "merged2 = ratings_dates.merge(\n",
    "    movies,\n",
    "    on='movieId',\n",
    "    how='outer'\n",
    ")\n",
    "'Number of rows in table \"merged2\":',merged2.shape[0]\n",
    "merged2.tail()\n",
    "\"\"\"Оказывается, в таблице movies содержались фильмы, которым ещё не были выставлены оценки.\n",
    "В результате объединения типом full outer информация о фильмах перенеслась из таблицы movies в\n",
    "результирующую таблицу. Однако, поскольку оценки фильмам ещё не были выставлены, соответствующие\n",
    "столбцы таблицы ratings_dates заполнились пропусками(NaN).Такие фильмы были записаны в конец таблицы\n",
    "Метод merge() с внешним (outer) типом объединения может использоваться как аналог метода concat()\n",
    "при объединении таблиц с одинаковой структурой (одинаковые количество и названия столбцов) по\n",
    "строкам. В таком случае все одноимённые столбцы таблиц будут считаться ключевыми.\"\"\"\n",
    "#Рассмотрим пример: объединим таблицы ratings1 и ratings2, как мы уже делали раньше, \n",
    "# но теперь используем метод merge():\n",
    "merge_ratings = ratings1_df.merge(ratings2_df, how='outer')\n",
    "'Number of raws in table \"merge_ratings:\"', merge_ratings.shape[0]\n",
    "merge_ratings\n",
    "\"\"\"Обратите внимание, что при использовании метода merge() для склейки двух таблиц у нас\n",
    "автоматически пропали дубликаты, которые мы видели при использовании метода concat(). Это\n",
    "особенность метода merge() — автоматическое удаление дублей.\"\"\"\n",
    "#Дано две исходных таблицы:\n",
    "data_1 = pd.DataFrame({'Value':[100,45,80],\n",
    "                      'Group':[1,4,5]},\n",
    "                      index=['I0','I1','I2'])\n",
    "data_1\n",
    "data_2 = pd.DataFrame({'Company': ['Google', 'Amazon', 'Facebook'],\n",
    "                       \"Add\": ['S0', 'S1', 'S7']},\n",
    "                      index = ['I0','I1', 'I3'])\n",
    "data_2\n",
    "data_joined_1 = data_1.join(data_2, how='inner')\n",
    "data_joined_2 = data_1.join(data_2, how='outer')\n",
    "data_joined_3 = data_1.join(data_2, how='left')\n",
    "data_joined_4 = data_1.join(data_2, how='right')\n",
    "data_joined_1\n",
    "\n",
    "a = pd.DataFrame({'A': ['a','b','c'],'B': [103, 214, 124], 'C': [1, 4, 2]})\n",
    "b = pd.DataFrame({'V': ['d', 'b', 'c'], 'U': [1393.7, 9382.2, 1904.5], 'C': [1, 3, 2]})\n",
    "ex_1 = a.join(b, how='inner', rsuffix='_r')\n",
    "ex_2 = a.merge(b, how='left', on='C')\n",
    "ex_3 = b.join(a.set_index('C'), how='right', on='C')\n",
    "ex_4 = a.merge(b, how='right', on='C')\n",
    "ex_5 = a.merge(b, how='inner', on='C')\n",
    "ex_3\n",
    "\n",
    "#ЗАДАНИЕ 7.5 \n",
    "#Даны две таблицы: items_df, в которой содержится информация о наличии товаров на складе,\n",
    "#и purchase_df — с данными о покупках товаров.\n",
    "items_df = pd.DataFrame({\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 100132, 312394], \n",
    "    'vendor': ['Samsung', 'LG', 'Apple', 'Apple', 'LG', 'Apple', 'Samsung', 'Samsung', 'LG', 'ZTE'],\n",
    "    'stock_count': [54, 33, 122, 18, 102, 43, 77, 143, 60, 19]\n",
    "})\n",
    "purchase_df = pd.DataFrame({\n",
    "    'purchase_id': [101, 101, 101, 112, 121, 145, 145, 145, 145, 221],\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 103845, 100132], \n",
    "    'price': [13900, 5330, 38200, 49990, 9890, 33000, 67500, 34500, 89900, 11400]\n",
    "})\n",
    "\"\"\"Информация в таблицах представлена в виде следующих столбцов:\n",
    "item_id — идентификатор модели;\n",
    "vendor — производитель модели;\n",
    "stock_count — имеющееся на складе количество данных моделей (в штуках);\n",
    "purchase_id — идентификатор покупки;\n",
    "price — стоимость модели в покупке.\"\"\"\n",
    "#Сформируйте DataFrame merged, в котором в результате объединения purchase_df и items_df останутся\n",
    "#модели, которые учтены на складе и имели продажи.\n",
    "#Из таблицы merged найдите суммарную выручку, которую можно было бы получить от продажи всех товаров,\n",
    "#которые учтены на складе и имели продажи. Результат занесите в переменную income.\n",
    "\n",
    "df_merged = items_df.merge(purchase_df, how='inner', on='item_id')\n",
    "df_merged\n",
    "income = sum (df_merged['stock_count'] * df_merged['price'])#.sum()\n",
    "income"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
